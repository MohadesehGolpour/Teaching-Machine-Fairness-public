{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["EkSEqPoJG4Ie","M3BYLWVzIh0v"],"authorship_tag":"ABX9TyOEOdFyUhcUzMZmsg1eEcUw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6n7E0uOz99vs"},"outputs":[],"source":["!pip install datasets\n","!pip install evaluate\n","!pip install transformers[torch]\n","!pip install accelerate -U"]},{"cell_type":"code","source":["from datasets import load_dataset, load_metric\n","from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification\n","from transformers import get_scheduler, AdamW\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from tqdm.auto import tqdm\n","import numpy as np\n","import evaluate\n","import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc\n","import os\n","from datasets import concatenate_datasets, Dataset\n","from huggingface_hub import HfApi\n","from huggingface_hub import Repository\n","from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay\n","from torch.nn import MSELoss\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.utils import resample\n","import itertools"],"metadata":{"id":"pnw1apxrqWWy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preparing the f dataset"],"metadata":{"id":"jrS6jHH9qoEd"}},{"cell_type":"code","source":["bias_in_bios_dataset = load_dataset(\"LabHC/bias_in_bios\")\n","bias_in_bios_dataset"],"metadata":{"id":"vUp97MvXqaER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_pandas = pd.DataFrame(bias_in_bios_dataset['train'])\n","labels = ['0 : Accountant', '1 : Architect', '2 : Attorney', '3 : Chiropractor', '4 : Comedian', '5 : Composer',\n","          '6 : Dentist', '7 : Dietitian', '8 : DJ', '9 : Film Maker', '10 : Interior Designer', '11 : Journalist',\n","          '12 : Model', '13 : Nurse', '14 : Painter', '15 : Paralegal', '16 : Pastor', '17 : Personal Trainer',\n","          '18 : Photographer', '19 : Physician', '20 : Poet', '21 : Professor', '22 : Psychologist', '23 : Rapper',\n","          '24 : Software Engineer', '25 : Surgeon', '26 : Teacher', '27 : Yoga Teacher']\n","gen = ['Male', 'Female']\n","data = pd.crosstab(df_pandas['profession'], df_pandas['gender'])\n","plt.figure(figsize=(5,8))\n","sns.heatmap(data, annot=True, fmt = '.0f', cmap=\"YlGnBu\" , yticklabels=labels, xticklabels=gen, annot_kws={\"size\":10})\n","plt.xlabel('Gender')\n","plt.ylabel('Profession')\n","plt.title('Value Counts Grouped by gender and proffession')\n","\n","plt.show()"],"metadata":{"id":"83aw0hv9qsgw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_pandas = df_pandas.loc[df_pandas['profession'].isin([13,19])]\n","df_pandas\n","labels = ['0 : Nurse', '1 : Physician']\n","gen = ['Male', 'Female']\n","data = pd.crosstab(df_pandas['profession'], df_pandas['gender'])\n","plt.figure(figsize=(5,4))\n","sns.heatmap(data, annot=True, fmt = '.0f', cmap=\"YlGnBu\" , yticklabels=labels, xticklabels=gen, annot_kws={\"size\":10})\n","plt.xlabel('Gender')\n","plt.ylabel('Profession')\n","plt.title('Value Counts Grouped by gender and proffession')\n","\n","plt.show()"],"metadata":{"id":"HUYdphsLqu6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nurse = 0   Physician = 1\n","def filter_and_change_values(example):\n","    if example['profession'] == 13:\n","        example['profession'] = 0\n","    elif example['profession'] == 19:\n","        example['profession'] = 1\n","    else:\n","        example['profession'] = None\n","    return example\n","\n","for split in ['train', 'dev', 'test']:\n","    bias_in_bios_dataset[split] = bias_in_bios_dataset[split].map(filter_and_change_values).filter(lambda x: x['profession'] is not None)\n"],"metadata":{"id":"z0m0pWD2qxr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bias_in_bios_dataset"],"metadata":{"id":"AWSP2m1rqzzh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.DataFrame(bias_in_bios_dataset['train'])\n","\n","majority_class = data[data['profession'] == 1]\n","minority_class = data[data['profession'] == 0]\n","\n","# Oversample minority class\n","minority_class_oversampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n","\n","balanced_data = pd.concat([majority_class, minority_class_oversampled])\n","\n","balanced_dataset = Dataset.from_pandas(balanced_data, split='train')\n","\n","labels_pandas = pd.DataFrame(balanced_data['profession'])\n","class_counts = labels_pandas.value_counts().sort_values(ascending=False)\n","print(class_counts)\n","\n","bias_in_bios_dataset['train'] = balanced_dataset"],"metadata":{"id":"WsHv1vZVq29p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = ['0 : Nurse', '1 : Physician']\n","gen = ['0 : Male', '1 : Female']\n","data = pd.crosstab(balanced_data['profession'], balanced_data['gender'])\n","plt.figure(figsize=(5,4))\n","sns.heatmap(data, annot=True, fmt = '.0f', cmap=\"YlGnBu\" , yticklabels=labels, xticklabels=gen, annot_kws={\"size\":10})\n","plt.xlabel('Gender')\n","plt.ylabel('Profession')\n","plt.title('Value Counts Grouped by gender and proffession')\n","\n","plt.show()"],"metadata":{"id":"jszDfDczq5lc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['hard_text'], truncation=True)\n","\n","tokenized_datasets = bias_in_bios_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['hard_text'])\n","tokenized_datasets = tokenized_datasets.rename_column('profession','labels')\n","tokenized_datasets = tokenized_datasets.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"df1ILFjiq8Ft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(\n","    tokenized_datasets['train'], shuffle=True, batch_size=20, collate_fn=data_collator\n","#   tokenized_datasets['train'], batch_size=20, collate_fn=data_collator\n",")\n","eval_dataloader = DataLoader(\n","    tokenized_datasets['dev'], batch_size=20, collate_fn=data_collator\n",")\n","test_dataloader = DataLoader(\n","    tokenized_datasets['test'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"c6Bd_LIqq-w2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fine-tuning f Model"],"metadata":{"id":"6zOEyd9qrJur"}},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint = \"bert-base-uncased\"\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","\n","model.to(device)\n","print(device)"],"metadata":{"id":"Tub28neErLp6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(), lr=5e-5)\n","num_epochs = 1\n","num_training_steps = num_epochs*len(train_dataloader)\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"3krtl_g1rOIC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","gc.collect()\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"],"metadata":{"id":"9_gfecurrSuV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["progress_bar = tqdm(range(num_training_steps))\n","\n","model.train()\n","for epoch in range(num_epochs):\n","  for batch in train_dataloader:\n","    labels = batch['labels'].to(device)\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    token_type_ids = batch['token_type_ids'].to(device)\n","\n","    outputs = model(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","    loss = outputs.loss\n","    loss.backward()\n","\n","    optimizer.step()\n","    lr_scheduler.step()\n","    optimizer.zero_grad()\n","    progress_bar.update(1)"],"metadata":{"id":"V1aom6LMrThE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/f_x\"\n","access_token = \"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\"\n","\n","# Save the model and tokenizer to the Hub\n","model.push_to_hub(hub_repo_name, use_auth_token=access_token)\n","tokenizer.push_to_hub(hub_repo_name, use_auth_token=access_token)"],"metadata":{"id":"DJg2VAMXrVSE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation of f"],"metadata":{"id":"xUQMjF5orexu"}},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","# Load the model saved on huggingface\n","checkpoint = \"MoGP/f_x\"\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","\n","model.to(device)\n","print(device)"],"metadata":{"id":"-zI6ThVnrZlG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = []\n","y_pred = []\n","gender = []\n","metric = load_metric(\"glue\",\"mrpc\")\n","model.eval()\n","for batch in test_dataloader:\n","  labels = batch['labels'].to(device)\n","  input_ids = batch['input_ids'].to(device)\n","  attention_mask = batch['attention_mask'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  sex = batch['gender'].to(device)\n","  with torch.no_grad():\n","    outputs = model(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","  logits = outputs.logits\n","  predictions = torch.argmax(logits, dim=-1)\n","  metric.add_batch(predictions=predictions, references=labels)\n","  pred = predictions.cpu().numpy()\n","  lab = labels.cpu().numpy()\n","  gen = sex.cpu().numpy()\n","  y_pred.append(pred)\n","  y_true.append(lab)\n","  gender.append(gen)\n","metric.compute()"],"metadata":{"id":"R84mHEzdR3Cg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = np.concatenate(y_pred)\n","y_true = np.concatenate(y_true)\n","gender = np.concatenate(gender)\n","\n","conf_matrix = confusion_matrix(y_true,y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)"],"metadata":{"id":"-s_RRsCrU3cI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0,1]) #nurse,physician\n","disp.plot()\n","plt.savefig(\"conf.png\")\n","plt.show()"],"metadata":{"id":"0u1gQT-oWvAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fairness metrics : priviledged class - discriminated class\n","SP = np.mean(y_pred[gender==0]) - np.mean(y_pred[gender==1])\n","EO = np.mean(y_pred[(y_true==1) & (gender==0)]) - np.mean(y_pred[(y_true==1) & (gender==1)])\n","TNRD = np.mean(y_pred[(y_true==0) & (gender==1)]) - np.mean(y_pred[(y_true==0) & (gender==0)]) # (1-fpf)-(1-fpm) = fpm-fpf\n","print(\"Statistical Parity: \",SP)\n","print(\"True Positive Rate Difference (Equal Opportunity): \",EO)\n","print(\"True Negative Rate Difference: \",TNRD)"],"metadata":{"id":"vYEYnTpTWv3j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true_flat = y_true\n","y_pred_flat = y_pred\n","gender_flat = gender\n","\n","unique_genders = set(gender_flat)\n","\n","# Plot confusion matrix for each gender\n","for gender in unique_genders:\n","    y_true_gender = [y_true_flat[i] for i in range(len(y_true_flat)) if gender_flat[i] == gender]\n","    y_pred_gender = [y_pred_flat[i] for i in range(len(y_pred_flat)) if gender_flat[i] == gender]\n","\n","    cm = confusion_matrix(y_true_gender, y_pred_gender)\n","\n","    profession = ['0 : Nurse', '1 : Physician']\n","    plt.figure(figsize=(6, 4))\n","    sns.set(font_scale=1.5)\n","    sns.heatmap(cm/np.sum(cm), annot=True, yticklabels=profession, xticklabels=profession, fmt='.2%', cmap='Blues', cbar=False)\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    if gender==0:\n","      gen = 'Male'\n","    else:\n","      gen = 'Female'\n","    plt.title(f'Confusion Matrix for Gender: {gen}')\n","    plt.show()"],"metadata":{"id":"Rnv0M56OWyZF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating the g dataset"],"metadata":{"id":"dYPynYJlwRHv"}},{"cell_type":"code","source":["g_labels = []\n","\n","def calculate_new_labels(predictions, labels, sensitive_attribute):\n","    new_labels = np.zeros_like(predictions)\n","    for i in range(len(predictions)):\n","      # False negative for women\n","      if labels[i] == 1 and predictions[i] == 0 and sensitive_attribute[i] == 1:\n","          new_labels[i] = 1\n","      # False positive for men\n","      elif labels[i] == 0 and predictions[i] == 1 and sensitive_attribute[i] == 0:\n","          new_labels[i] = -1\n","      # The rest of the wrong predictions (false negative for men and false positive for women) - should I add this?\n","      elif (labels[i] == 0 and predictions[i] == 1 and sensitive_attribute[i] == 1) or (labels[i] == 1 and predictions[i] == 0 and sensitive_attribute[i] == 0):\n","        new_labels[i] = -2\n","    return new_labels\n","\n","for batch in train_dataloader:\n","  labels = batch['labels'].to(device)\n","  input_ids = batch['input_ids'].to(device)\n","  attention_mask = batch['attention_mask'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  sensitive_attribute = batch['gender'].to(device)\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","  logits = outputs.logits\n","  predictions = torch.argmax(logits, dim=-1)\n","\n","\n","  predictions_np = predictions.cpu().numpy()\n","  labels_np = labels.cpu().numpy()\n","  sensitive_attribute_np = sensitive_attribute.cpu().numpy()\n","\n","\n","  new_labels = calculate_new_labels(predictions_np, labels_np, sensitive_attribute_np)\n","  g_labels.append(new_labels)"],"metadata":{"id":"qRNi7IbMW2QR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["G_labels = np.concatenate(g_labels).ravel()\n","print(G_labels)"],"metadata":{"id":"4ZqDmKIDwZ1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_pandas = pd.DataFrame(G_labels)\n","class_counts = labels_pandas.value_counts().sort_values(ascending=False)\n","print(class_counts)"],"metadata":{"id":"FAJpoOjowamI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts = bias_in_bios_dataset['train']['hard_text']\n","\n","data_dict = {\n","    'texts': texts,\n","    'labels': G_labels\n","}\n","\n","datasets_g = Dataset.from_dict(data_dict)"],"metadata":{"id":"N8mWzPFtweVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datasets_g = datasets_g.filter(lambda x: x['labels'] != -2)\n","dataset_g = pd.DataFrame(datasets_g)\n","dataset_g.to_csv(\"datasetwt.csv\", index=False)  # The index parameter controls whether to save the index column"],"metadata":{"id":"7w3lwgGewglR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/g_dataset_text_new\"\n","access_token = \"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\"\n","csv_file_path = \"datasetwt.csv\"\n","\n","api = HfApi()\n","\n","commit_message = \"Add dataset file\"\n","api.upload_file(\n","    path_or_fileobj=csv_file_path,\n","    path_in_repo=\"datasetwt.csv\",\n","    repo_id=hub_repo_name,\n","    token=access_token,\n","    commit_message=commit_message,\n","    repo_type=\"dataset\"\n",")"],"metadata":{"id":"3HXLjvaRwlV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training the g function"],"metadata":{"id":"Xkb0rx1Ewc7e"}},{"cell_type":"code","source":["datasets_g = load_dataset(\"MoGP/g_dataset_text_new\")\n","datasets_g"],"metadata":{"id":"EPLPLmgfw5hX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['texts'], truncation=True)\n","\n","tokenized_datasets_g = datasets_g.map(tokenize_function, batched=True)\n","tokenized_datasets_g = tokenized_datasets_g.remove_columns(['texts'])\n","tokenized_datasets_g = tokenized_datasets_g.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"kDzhqsGXw7n4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = tokenized_datasets_g['train'].to_pandas()\n","zeros_data = data[data['labels'] == 0]\n","\n","zeros_sample = zeros_data.sample(frac=0.03, random_state=42)\n","non_zeros_data = data[data['labels'] != 0]\n","new_data = pd.concat([zeros_sample, non_zeros_data])\n","\n","labels_pandas = pd.DataFrame(new_data['labels'])\n","class_counts = labels_pandas.value_counts().sort_values(ascending=False)\n","print(class_counts)\n","\n","new_dataset = Dataset.from_pandas(new_data)\n","\n","tokenized_datasets_g['train'] = new_dataset\n","new_dataset"],"metadata":{"id":"Y76FnQNyw9ci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute class weights\n","labels = tokenized_datasets_g['train']['labels']\n","labels = [2 if label == -1 else label for label in labels]\n","\n","class_counts = np.bincount(labels)\n","class_weights = 1.0 / class_counts\n","weights = class_weights[labels]\n","\n","# Create sampler\n","sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)"],"metadata":{"id":"QaGvxjEZw_NS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader_g = DataLoader(\n","    tokenized_datasets_g['train'], batch_size=20, sampler=sampler, collate_fn=data_collator\n",")"],"metadata":{"id":"H6Kq7rXvxBko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint = \"bert-base-uncased\"\n","model_g = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n","\n","model_g.to(device)\n","print(device)"],"metadata":{"id":"_rcpqdwdxDnE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_g = AdamW(model_g.parameters(), lr=5e-5)\n","num_epochs = 3\n","num_training_steps = num_epochs*len(train_dataloader_g)\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer_g,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"8gjbcuAoxGyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["progress_bar = tqdm(range(num_training_steps))\n","\n","model_g.train()\n","for epoch in range(num_epochs):\n","  for batch in train_dataloader_g:\n","    labels = batch['labels']\n","    labels[labels == -1] = 2\n","    labels = labels.to(device)\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    token_type_ids = batch['token_type_ids'].to(device)\n","\n","    outputs = model_g(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","    loss = outputs.loss\n","    loss.backward()\n","\n","    optimizer_g.step()\n","    lr_scheduler.step()\n","    optimizer_g.zero_grad()\n","    progress_bar.update(1)"],"metadata":{"id":"oYQnkaCSxI8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/g_x_new\"\n","access_token = \"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\"\n","\n","# Save the model and tokenizer to the Hub\n","model_g.push_to_hub(hub_repo_name, use_auth_token=access_token)\n","tokenizer.push_to_hub(hub_repo_name, use_auth_token=access_token)"],"metadata":{"id":"j_9QfvQ3xJtE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation of g"],"metadata":{"id":"gXiEGIeHxP4O"}},{"cell_type":"code","source":["datasets_g = load_dataset(\"MoGP/g_test_set_new\")\n","datasets_g"],"metadata":{"id":"FqIcw_cyxLhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['texts'], truncation=True)\n","\n","tokenized_datasets_g = datasets_g.map(tokenize_function, batched=True)\n","tokenized_datasets_g = tokenized_datasets_g.remove_columns(['texts'])\n","tokenized_datasets_g = tokenized_datasets_g.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"9aW65Z0wxTzz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataloader_g = DataLoader(\n","    tokenized_datasets_g['train'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"ObZkdlr4xVnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint = \"MoGP/g_x_new\"\n","model_g = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n","\n","model_g.to(device)\n","print(device)"],"metadata":{"id":"wi09eZ27xXNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = []\n","y_pred = []\n","accuracy_metric = load_metric(\"accuracy\")\n","f1_metric = load_metric(\"f1\")\n","\n","model_g.eval()\n","for batch in test_dataloader_g:\n","  labels = batch['labels']\n","  labels[labels == -1] = 2\n","  labels = labels.to(device)\n","  input_ids = batch['input_ids'].to(device)\n","  attention_mask = batch['attention_mask'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  with torch.no_grad():\n","    outputs = model_g(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","  logits = outputs.logits\n","  predictions = torch.argmax(logits, dim=-1)\n","  accuracy_metric.add_batch(predictions=predictions, references=labels)\n","  f1_metric.add_batch(predictions=predictions, references=labels)\n","  pred = predictions.cpu().numpy()\n","  lab = labels.cpu().numpy()\n","  y_pred.append(pred)\n","  y_true.append(lab)\n","acc = accuracy_metric.compute()\n","f1 = f1_metric.compute(average=\"weighted\")\n","print(acc)\n","print(f1)"],"metadata":{"id":"s3tEIWcwxZpA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = np.concatenate(y_pred)\n","y_true = np.concatenate(y_true)\n","\n","conf_matrix = confusion_matrix(y_true,y_pred)\n","multilabel_conf_matrix = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0, 1])\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"Confusion Matrix for each class:\")\n","print(multilabel_conf_matrix)"],"metadata":{"id":"V4PlOapQxh7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.set(font_scale=1.5)\n","sns.heatmap(conf_matrix/np.sum(conf_matrix), fmt='.2%', yticklabels=[0,1,-1], xticklabels=[0,1,-1], annot=True, cmap='Purples', cbar=False)\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.savefig(\"conf.png\")\n","plt.show()"],"metadata":{"id":"8zMrhOf3xj6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training the g function - Regression"],"metadata":{"id":"pQ8RIYj8E6tx"}},{"cell_type":"code","source":["datasets_g = load_dataset(\"MoGP/g_dataset_text_new\")\n","datasets_g"],"metadata":{"id":"RSHDq3zcE7Cs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['texts'], truncation=True)\n","\n","tokenized_datasets_g = datasets_g.map(tokenize_function, batched=True)\n","tokenized_datasets_g = tokenized_datasets_g.remove_columns(['texts'])\n","tokenized_datasets_g = tokenized_datasets_g.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"U-FMVngNE81C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = tokenized_datasets_g['train'].to_pandas()\n","zeros_data = data[data['labels'] == 0]\n","\n","zeros_sample = zeros_data.sample(frac=0.03, random_state=42)\n","non_zeros_data = data[data['labels'] != 0]\n","new_data = pd.concat([zeros_sample, non_zeros_data])\n","\n","labels_pandas = pd.DataFrame(new_data['labels'])\n","class_counts = labels_pandas.value_counts().sort_values(ascending=False)\n","print(class_counts)\n","\n","new_dataset = Dataset.from_pandas(new_data)\n","\n","tokenized_datasets_g['train'] = new_dataset\n","new_dataset"],"metadata":{"id":"ahveYBNDE-64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bin the target values\n","labels = np.array(tokenized_datasets_g['train']['labels'])\n","num_bins = 10\n","bins = np.linspace(np.min(labels), np.max(labels), num_bins)\n","binned_labels = np.digitize(labels, bins) - 1  # Bin indices start at 0\n","\n","# Compute class weights\n","class_counts = np.bincount(binned_labels)\n","class_weights = 1.0 / class_counts\n","weights = class_weights[binned_labels]\n","\n","# Create sampler\n","sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)"],"metadata":{"id":"ihTvQ3hFFBWr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader_g = DataLoader(\n","    tokenized_datasets_g['train'], batch_size=20, sampler=sampler, collate_fn=data_collator\n",")"],"metadata":{"id":"2K3Z9BjDFWCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint = \"bert-base-uncased\"\n","model_g_reg = AutoModelForSequenceClassification.from_pretrained(checkpoint, problem_type=\"regression\", num_labels=1)\n","\n","model_g_reg.to(device)\n","print(device)"],"metadata":{"id":"1pmHvl_KFYIJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_g = AdamW(model_g_reg.parameters(), lr=5e-5)\n","num_epochs = 3\n","num_training_steps = num_epochs*len(train_dataloader_g)\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer_g,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"-j-aLAemFaBl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["progress_bar = tqdm(range(num_training_steps))\n","# Loss function for regression\n","loss_fn = MSELoss()\n","\n","model_g_reg.train()\n","for epoch in range(num_epochs):\n","  for batch in train_dataloader_g:\n","    labels = batch['labels'].to(device)\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    token_type_ids = batch['token_type_ids'].to(device)\n","\n","    outputs = model_g_reg(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","    loss = loss_fn(outputs.logits.squeeze(), labels.float())\n","\n","    loss.backward()\n","\n","    optimizer_g.step()\n","    lr_scheduler.step()\n","    optimizer_g.zero_grad()\n","    progress_bar.update(1)"],"metadata":{"id":"uTdBKj36FcZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/g_x_reg_new\"\n","access_token = \"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\"\n","\n","# Save the model and tokenizer to the Hub\n","model_g_reg.push_to_hub(hub_repo_name, use_auth_token=access_token)\n","tokenizer.push_to_hub(hub_repo_name, use_auth_token=access_token)"],"metadata":{"id":"SlzugjkXFcOK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation of g - Regression"],"metadata":{"id":"2e_Ia5jDGa-C"}},{"cell_type":"code","source":["datasets_g = load_dataset(\"MoGP/g_test_set_new\")\n","datasets_g"],"metadata":{"id":"tAadEF4-GbWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['texts'], truncation=True)\n","\n","tokenized_datasets_g = datasets_g.map(tokenize_function, batched=True)\n","tokenized_datasets_g = tokenized_datasets_g.remove_columns(['texts'])\n","tokenized_datasets_g = tokenized_datasets_g.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"hkGhDUBlGeA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataloader_g = DataLoader(\n","    tokenized_datasets_g['train'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"bh0gUr5_Gf5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint = \"MoGP/g_x_reg_new\"\n","model_g_reg = AutoModelForSequenceClassification.from_pretrained(checkpoint, problem_type=\"regression\", num_labels=1)\n","\n","model_g_reg.to(device)\n","print(device)"],"metadata":{"id":"R0FCMvdrGiMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = []\n","y_pred = []\n","\n","model_g_reg.eval()\n","for batch in test_dataloader_g:\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    labels = batch['labels'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model_g_reg(input_ids, attention_mask=attention_mask)\n","    logits = outputs.logits\n","\n","    # Since it's a regression task, logits should already be the predicted continuous values\n","    predictions = logits.squeeze().cpu().numpy()\n","    lab = labels.cpu().numpy()\n","\n","    y_pred.append(predictions)\n","    y_true.append(lab)"],"metadata":{"id":"HJdOkNBVGlBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = np.concatenate(y_pred)\n","y_true = np.concatenate(y_true)\n","\n","mse = mean_squared_error(y_true, y_pred)\n","mae = mean_absolute_error(y_true, y_pred)\n","\n","print(f\"Mean Squared Error: {mse}\")\n","print(f\"Mean Absolute Error: {mae}\")"],"metadata":{"id":"GCvyndURGmtK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for label in [-1, 0, 1]:\n","    y_pred_label = y_pred[(y_true==label)]\n","    y_true_label = y_true[(y_true==label)]\n","    mse = mean_squared_error(y_true_label, y_pred_label)\n","    mae = mean_absolute_error(y_true_label, y_pred_label)\n","\n","    print(f\"Mean Squared Error for label {label}: {mse}\")\n","    print(f\"Mean Absolute Error for label {label}: {mae}\")\n","    print(\"----------------------------------------------------\")"],"metadata":{"id":"YtLnJFS9Go71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = {\n","    'y_true': y_true,\n","    'y_pred': y_pred\n","}\n","df = pd.DataFrame(res)"],"metadata":{"id":"raEBC5_gGtvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = [-1, 0, 1]\n","\n","for label in labels:\n","    fig, ax = plt.subplots(figsize=(4, 4))\n","    subset = df[df['y_true'] == label]\n","    predictions = subset['y_pred']\n","\n","    # Scatter plot for predictions\n","    ax.scatter(subset.index, predictions, color='blue', label='Predictions', s=10)\n","\n","    # Horizontal line for the actual label\n","    ax.axhline(y=label, color='red', linestyle='--', linewidth=2, label=f'Actual label: {label}')\n","\n","    ax.set_xlabel('Data point index')\n","    ax.set_ylabel('Prediction')\n","    ax.set_title(f'Scatter plot for label {label}')\n","    ax.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"RbbR71jrGved"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using g to create f' function"],"metadata":{"id":"4D1JPa85Gz44"}},{"cell_type":"markdown","source":["## Creating new dataset for f' with results of g and f"],"metadata":{"id":"EkSEqPoJG4Ie"}},{"cell_type":"code","source":["bias_in_bios_dataset = load_dataset(\"LabHC/bias_in_bios\")\n","bias_in_bios_dataset"],"metadata":{"id":"mZpImeX2Gwiq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nurse = 0   Physician = 1\n","def filter_and_change_values(example):\n","    if example['profession'] == 13:\n","        example['profession'] = 0\n","    elif example['profession'] == 19:\n","        example['profession'] = 1\n","    else:\n","        example['profession'] = None\n","    return example\n","\n","for split in ['train', 'dev', 'test']:\n","    bias_in_bios_dataset[split] = bias_in_bios_dataset[split].map(filter_and_change_values).filter(lambda x: x['profession'] is not None)\n"],"metadata":{"id":"PBqJkbezG7Um"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['hard_text'], truncation=True)\n","\n","tokenized_datasets = bias_in_bios_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['hard_text'])\n","tokenized_datasets = tokenized_datasets.rename_column('profession','labels')\n","tokenized_datasets = tokenized_datasets.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"7lLrBNubG9qE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_dataloader = DataLoader(\n","   tokenized_datasets['dev'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"RGPqVJvjHLCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint_f = \"MoGP/f_x\"\n","model_f = AutoModelForSequenceClassification.from_pretrained(checkpoint_f, num_labels=2)\n","model_f.to(device)\n","\n","checkpoint_g = \"MoGP/g_x_new\"\n","model_g = AutoModelForSequenceClassification.from_pretrained(checkpoint_g, num_labels=3)\n","model_g.to(device)"],"metadata":{"id":"1ASIGSmOHM0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f_labels = []\n","g_labels = []\n","\n","model_f.eval()\n","model_g.eval()\n","\n","for batch in dev_dataloader:\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    token_type_ids = batch['token_type_ids'].to(device)\n","\n","    with torch.no_grad():\n","        outputs_f = model_f(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        outputs_g = model_g(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","\n","    f_logits = outputs_f.logits\n","    f_predictions = torch.nn.functional.softmax(f_logits, dim=-1)[:, 1].cpu().numpy()\n","\n","\n","    g_logits = outputs_g.logits\n","    g_predictions = torch.argmax(g_logits, dim=-1).cpu().numpy()\n","\n","    f_labels.extend(f_predictions)\n","    g_labels.extend(g_predictions)"],"metadata":{"id":"tYeK1tDEHPjH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_pandas = pd.DataFrame(g_labels)\n","class_counts = labels_pandas.value_counts().sort_values(ascending=False)\n","print(class_counts)"],"metadata":{"id":"KblgBDoCHRu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f_labels = np.array(f_labels)\n","g_labels = np.array(g_labels)\n","texts = bias_in_bios_dataset['dev']['hard_text']\n","labels = bias_in_bios_dataset['dev']['profession']\n","genders = bias_in_bios_dataset['dev']['gender']\n","\n","data_dict = {\n","    'hard_text': texts,\n","    'gender': genders,\n","    'labels': labels,\n","    'f_labels': f_labels,\n","    'g_labels': g_labels\n","}\n","\n","datasets_f_prime = Dataset.from_dict(data_dict)\n","datasets_f_prime = datasets_f_prime.filter(lambda x: x['g_labels'] != -2)\n","datasets_f_prime"],"metadata":{"id":"0IcyHNHvHTmC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_g = pd.DataFrame(datasets_f_prime)\n","dataset_g.to_csv(\"fpdataset.csv\", index=False)"],"metadata":{"id":"YB400E3OHVov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/f_prime_dataset_dev_new\"\n","access_token = \"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\"\n","csv_file_path = \"fpdataset.csv\"\n","\n","api = HfApi()\n","\n","commit_message = \"Add dataset file\"\n","api.upload_file(\n","    path_or_fileobj=csv_file_path,\n","    path_in_repo=\"fpdataset.csv\",\n","    repo_id=hub_repo_name,\n","    token=access_token,\n","    commit_message=commit_message,\n","    repo_type=\"dataset\"\n",")"],"metadata":{"id":"NdKrMIIOHXuW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preparing the training set for f'\n","\n","\n"],"metadata":{"id":"mFzbhRYIHZ8d"}},{"cell_type":"code","source":["f_prime_dataset_train = load_dataset(\"MoGP/f_prime_dataset_new\")\n","f_prime_dataset_dev = load_dataset(\"MoGP/f_prime_dataset_dev_new\")"],"metadata":{"id":"N5I_FwoRHfrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = f_prime_dataset_train['train'].to_pandas()\n","\n","majority_class = data[data['g_labels'] == 1]\n","minority_class = data[data['g_labels'] == -1]\n","zero_class = data[data['g_labels'] == 0]\n","\n","# remove some zeros randomly\n","zeros_sample = zero_class.sample(frac=0.113, random_state=42)\n","\n","# Oversample minority class\n","minority_class_oversampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n","\n","balanced_data = pd.concat([majority_class, minority_class_oversampled, zeros_sample])\n","balanced_dataset = Dataset.from_pandas(balanced_data, split='train')"],"metadata":{"id":"kUfXB9klHnVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_pandas = pd.DataFrame(balanced_dataset['g_labels'])\n","class_counts = labels_pandas.value_counts().sort_values(ascending=False)\n","print(class_counts)"],"metadata":{"id":"i88eGka6HujU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['hard_text'], truncation=True)\n","\n","tokenized_datasets = balanced_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['hard_text'])\n","tokenized_datasets = tokenized_datasets.with_format('torch')\n","\n","\n","tokenized_datasets_dev = f_prime_dataset_dev.map(tokenize_function, batched=True)\n","tokenized_datasets_dev = tokenized_datasets_dev.remove_columns(['hard_text'])\n","tokenized_datasets_dev = tokenized_datasets_dev.with_format('torch')\n","\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"VAusbzHvHwa3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(\n","   tokenized_datasets, shuffle=True, batch_size=20, collate_fn=data_collator\n",")\n","\n","dev_dataloader = DataLoader(\n","   tokenized_datasets_dev['train'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"bXMxZiCJH4v_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine-tuning the hyperparameters:\n","alpha, learning rate, number of epochs\n"],"metadata":{"id":"ss1IvTB5IJkc"}},{"cell_type":"code","source":["def custom_loss(g_output, f_output, fprime_output, alpha=1.0):\n","    mse_loss = nn.MSELoss()\n","    regularization_term = mse_loss(f_output, fprime_output)\n","    left = torch.sum(g_output * fprime_output * -1)\n","    combined_loss = left + alpha * regularization_term\n","    return combined_loss"],"metadata":{"id":"NRcGpfhuIL1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_fprime(dev_dataloader_fprime, num_epochs=20, alpha=1.0, learning_rate=5e-6):\n","\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","    checkpoint = \"MoGP/f_x\"\n","    model_fprime = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","    model_fprime.to(device)\n","\n","    optimizer_fprime = AdamW(model_fprime.parameters(), lr=learning_rate)\n","    num_training_steps = num_epochs * len(dev_dataloader_fprime)\n","    lr_scheduler_fprime = get_scheduler(\n","        \"linear\",\n","        optimizer=optimizer_fprime,\n","        num_warmup_steps=0,\n","        num_training_steps=num_training_steps\n","    )\n","\n","    progress_bar = tqdm(range(num_training_steps))\n","    model_fprime.train()\n","    for epoch in range(num_epochs):\n","        for batch in dev_dataloader_fprime:\n","            labels = batch['labels'].to(device)\n","            y_g_output = batch['g_labels'].to(device)\n","            f_output = batch['f_labels'].to(device)\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            token_type_ids = batch['token_type_ids'].to(device)\n","\n","            outputs_fprime = model_fprime(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","            fprime_logits = outputs_fprime.logits\n","            fprime_output = torch.nn.functional.softmax(fprime_logits, dim=-1)[:, 1]\n","\n","            loss = custom_loss(y_g_output, f_output, fprime_output, alpha)\n","\n","            loss.backward()\n","\n","            optimizer_fprime.step()\n","            lr_scheduler_fprime.step()\n","            optimizer_fprime.zero_grad()\n","            progress_bar.update(1)\n","\n","    return model_fprime"],"metadata":{"id":"cPnB-Gy7IOXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, dataloader, device):\n","\n","    y_true = []\n","    y_pred = []\n","    gender = []\n","    metric = load_metric(\"glue\",\"mrpc\")\n","    model.eval()\n","\n","    for batch in dataloader:\n","      labels = batch['labels'].to(device)\n","      input_ids = batch['input_ids'].to(device)\n","      attention_mask = batch['attention_mask'].to(device)\n","      token_type_ids = batch['token_type_ids'].to(device)\n","      token_type_ids = batch['token_type_ids'].to(device)\n","      sex = batch['gender'].to(device)\n","      with torch.no_grad():\n","        outputs = model(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","      logits = outputs.logits\n","      predictions = torch.argmax(logits, dim=-1)\n","      metric.add_batch(predictions=predictions, references=labels)\n","      pred = predictions.cpu().numpy()\n","      lab = labels.cpu().numpy()\n","      gen = sex.cpu().numpy()\n","      y_pred.append(pred)\n","      y_true.append(lab)\n","      gender.append(gen)\n","\n","    eval = metric.compute()\n","    y_pred = np.concatenate(y_pred)\n","    y_true = np.concatenate(y_true)\n","    gender = np.concatenate(gender)\n","    EO = np.mean(y_pred[(y_true==1) & (gender==0)]) - np.mean(y_pred[(y_true==1) & (gender==1)])\n","    TNRD = np.mean(y_pred[(y_true==0) & (gender==1)]) - np.mean(y_pred[(y_true==0) & (gender==0)])\n","\n","    return eval['accuracy'], eval['f1'], EO, TNRD"],"metadata":{"id":"YCV8IETAIQHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def grid_search(train_dataloader, val_dataloader, param_grid, num_trials=1):\n","    best_acc = -1\n","    best_f1 = -1\n","    best_equal_opportunity = 1\n","    best_TNRD = 1\n","    best_params = None\n","    results = []\n","\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","    for params in param_grid:\n","        alpha, lr, epochs = params\n","        accuracies = []\n","        f1_scores = []\n","        equal_opportunity_scores = []\n","        true_negative_rate_differences = []\n","\n","        for _ in range(num_trials):\n","            model_fprime = train_fprime(train_dataloader, num_epochs=epochs, alpha=alpha, learning_rate=lr)\n","            accuracy, f1, EO, TNRD = evaluate_model(model_fprime, val_dataloader, device)\n","            accuracies.append(accuracy)\n","            f1_scores.append(f1)\n","            equal_opportunity_scores.append(EO)\n","            true_negative_rate_differences.append(TNRD)\n","\n","        avg_acc = np.mean(accuracies)\n","        avg_f1 = np.mean(f1_scores)\n","        avg_equal_opportunity = np.mean(equal_opportunity_scores)\n","        avg_TNRD = np.mean(true_negative_rate_differences)\n","        results.append((params, avg_acc, avg_f1, avg_equal_opportunity, avg_TNRD))\n","\n","        print(f\"Params: Alpha={params[0]}, Learning Rate={params[1]}, Epochs={params[2]} -> Accuracy:{avg_acc}, F1 Score: {avg_f1}, True Positive Difference Rate: {avg_equal_opportunity}, True Negative Difference Rate: {avg_TNRD}\")\n","\n","        if (avg_f1 >= best_f1) and (avg_equal_opportunity <= best_equal_opportunity):\n","            best_f1 = avg_f1\n","            best_equal_opportunity = avg_equal_opportunity\n","            best_params = params\n","\n","    return best_params, results"],"metadata":{"id":"HjMA0pfzIVS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alphas = [0.01, 0.2, 1, 3, 5, 7, 10.0, 15.0, 17.0, 20.0, 50.0, 100.0]\n","learning_rates = [5e-7, 1e-6, 5e-6, 1e-5]\n","num_epochs_list = [1]\n","\n","param_grid = list(itertools.product(alphas, learning_rates, num_epochs_list))\n","\n","best_params, all_results = grid_search(train_dataloader, dev_dataloader, param_grid, num_trials=1)"],"metadata":{"id":"QxgEX-53IXnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alphas = []\n","lrs  = []\n","epochss  = []\n","accs  = []\n","f1s  = []\n","equal_opportunities  = []\n","TNRDs = []\n","for params, acc, f1, equal_opportunity, TNRD in all_results:\n","    print(f\"Params: Alpha={params[0]}, Learning Rate={params[1]}, Epochs={params[2]} -> Accuracy:{acc}, F1 Score: {f1}, True Positive Difference Rate: {equal_opportunity}, True Negative Difference Rate: {TNRD}\")\n","    alphas.append(params[0])\n","    lrs.append(params[1])\n","    epochss.append(params[2])\n","    accs.append(acc)\n","    f1s.append(f1)\n","    equal_opportunities.append(equal_opportunity)\n","    TNRDs.append(TNRD)\n","res_dict = {\n","    'Alpha': alphas,\n","    'Learning Rate': lrs,\n","    'Epochs': epochss,\n","    'Accuracy': accs,\n","    'F1 Score': f1s,\n","    'TPDR': equal_opportunities,\n","    'TNDR': TNRDs\n","}\n","\n","index = np.arange(len(accs))\n","dataset_g = pd.DataFrame(res_dict, index=index)\n","dataset_g.to_csv(\"dataset.csv\")"],"metadata":{"id":"BEDFmYiyIeST"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Use the results from f and g classification to create f'"],"metadata":{"id":"M3BYLWVzIh0v"}},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","gc.collect()\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"],"metadata":{"id":"vQRF8co7IiMb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Approaches:\n","\n","\n","*   First approach:\n","\n","    argmin ∑ -g(x)f'(x)\n","    with a very small learning-rate\n","\n","*   Second approach:\n","\n","    argmin ∑ (-g(x)f'(x) + α|f(x)-f’(x)| )\n","\n","*   Third approach:\n","\n","    argmin ∑ (-g(x)logf'(x) + β(1-g(x)^2)|f(x)-f’(x)|)\n"],"metadata":{"id":"2xF9zZtfIzF5"}},{"cell_type":"code","source":["def custom_loss(g_output, f_output, fprime_output, alpha=10.0): #alpha=1.0\n","    mse_loss = nn.MSELoss()\n","    regularization_term = mse_loss(f_output, fprime_output)\n","    left = torch.sum((g_output * fprime_output * -1))\n","    combined_loss = left + alpha * regularization_term\n","    return combined_loss, left, regularization_term\n","\n","def train_fprime(train_dataloader_fprime, num_epochs=2, alpha=10.0): #alpha=1.0\n","    # Initialize f' model\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","    checkpoint = \"MoGP/f_x\"\n","    model_fprime = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","    model_fprime.to(device)\n","\n","    optimizer_fprime = AdamW(model_fprime.parameters(), lr=5e-6) # lr=5e-7\n","    num_training_steps = num_epochs * len(train_dataloader_fprime)\n","    lr_scheduler_fprime = get_scheduler(\n","        \"linear\",\n","        optimizer=optimizer_fprime,\n","        num_warmup_steps=0,\n","        num_training_steps=num_training_steps\n","    )\n","\n","    progress_bar = tqdm(range(num_training_steps))\n","    left_losses = []\n","    right_losses = []\n","    model_fprime.train()\n","    for epoch in range(num_epochs):\n","        for batch in train_dataloader_fprime:\n","            labels = batch['labels'].to(device)\n","            g_output = batch['g_labels'].to(device) #y_g_labels\n","            f_output = batch['f_labels'].to(device)\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            token_type_ids = batch['token_type_ids'].to(device)\n","\n","            # Get output from f'\n","\n","            outputs_fprime = model_fprime(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","            fprime_logits = outputs_fprime.logits\n","            fprime_output = torch.nn.functional.softmax(fprime_logits, dim=-1)[:, 1]  # Taking softmax and then second column\n","\n","            # Calculate custom loss\n","            loss, left, right = custom_loss(g_output, f_output, fprime_output, alpha)\n","\n","            loss.backward()\n","\n","            print(f\"g(x):{g_output}\")\n","            print(f\"f(x):{f_output}\")\n","            print(f\"f'(x):{fprime_output}\")\n","            print(\"______________________________________________\")\n","\n","            optimizer_fprime.step()\n","            lr_scheduler_fprime.step()\n","            optimizer_fprime.zero_grad()\n","            progress_bar.update(1)\n","            left_losses.append(left.item())\n","            right_losses.append(right.item())\n","\n","    return model_fprime, left_losses, right_losses\n","\n","model_fprime, left_losses, right_losses = train_fprime(train_dataloader, num_epochs=2, alpha=10.0)  #alpha=1.0\n"],"metadata":{"id":"tDdWoDNaIjul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the losses\n","#lsosses = left_losses[0::100]\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(left_losses, label='Left Loss')\n","plt.xlabel('Training Step')\n","plt.ylabel('Loss')\n","plt.title(\"Left Loss (Argmin -g(x)f'(x))\")\n","plt.legend()\n","\n","#rlosses = right_losses[0::100]\n","plt.subplot(1, 2, 2)\n","plt.plot(right_losses, label='Right Loss')\n","plt.xlabel('Training Step')\n","plt.ylabel('Loss')\n","plt.title(\"Regularization Term (|f(x)-f'(x)|)\")\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"asZXzsTeKWpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/f_prime_second_nikolas\"\n","access_token = \"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\"\n","\n","# Save the model and tokenizer to the Hub\n","model_fprime.push_to_hub(hub_repo_name, use_auth_token=access_token)\n","tokenizer.push_to_hub(hub_repo_name, use_auth_token=access_token)"],"metadata":{"id":"p_Bx3A9MKbGE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation of f'"],"metadata":{"id":"RQ-qmfYBKg-Z"}},{"cell_type":"code","source":["bias_in_bios_dataset = load_dataset(\"LabHC/bias_in_bios\")\n","bias_in_bios_dataset"],"metadata":{"id":"NIDb3CbCKePy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nurse = 0   Physician = 1\n","def filter_and_change_values(example):\n","    if example['profession'] == 13:\n","        example['profession'] = 0\n","    elif example['profession'] == 19:\n","        example['profession'] = 1\n","    else:\n","        example['profession'] = None\n","    return example\n","\n","for split in ['train', 'dev', 'test']:\n","    bias_in_bios_dataset[split] = bias_in_bios_dataset[split].map(filter_and_change_values).filter(lambda x: x['profession'] is not None)\n"],"metadata":{"id":"OKXMcu13KkA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['hard_text'], truncation=True)\n","\n","tokenized_datasets = bias_in_bios_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['hard_text'])\n","tokenized_datasets = tokenized_datasets.rename_column('profession','labels')\n","tokenized_datasets = tokenized_datasets.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"k4lUNK3yKl6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataloader = DataLoader(\n","   tokenized_datasets['test'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"TEdDUOMzKn70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint = \"MoGP/f_prime_second_nikolas\"\n","model_fprime = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","\n","model_fprime.to(device)\n","print(device)"],"metadata":{"id":"aBa31vpcKp5G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = []\n","y_pred = []\n","gender = []\n","metric = load_metric(\"glue\",\"mrpc\")\n","model_fprime.eval()\n","\n","for batch in test_dataloader:\n","  labels = batch['labels'].to(device)\n","  input_ids = batch['input_ids'].to(device)\n","  attention_mask = batch['attention_mask'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  sex = batch['gender'].to(device)\n","  with torch.no_grad():\n","    outputs = model_fprime(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","  logits = outputs.logits\n","  predictions = torch.argmax(logits, dim=-1)\n","  metric.add_batch(predictions=predictions, references=labels)\n","  pred = predictions.cpu().numpy()\n","  lab = labels.cpu().numpy()\n","  gen = sex.cpu().numpy()\n","  y_pred.append(pred)\n","  y_true.append(lab)\n","  gender.append(gen)\n","metric.compute()"],"metadata":{"id":"ePyHa9HAKses"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = np.concatenate(y_pred)\n","y_true = np.concatenate(y_true)\n","gender = np.concatenate(gender)\n","\n","conf_matrix = confusion_matrix(y_true,y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)"],"metadata":{"id":"-3zAm6zkKuQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0,1]) #nurse,physician\n","disp.plot()\n","plt.savefig(\"conf.png\")\n","plt.show()"],"metadata":{"id":"F8a3USSeKwON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fairness metrics : female=1 , male=0\n","SP = np.mean(y_pred[gender==0]) - np.mean(y_pred[gender==1])\n","EO = np.mean(y_pred[(y_true==1) & (gender==0)]) - np.mean(y_pred[(y_true==1) & (gender==1)])\n","TNRD = np.mean(y_pred[(y_true==0) & (gender==1)]) - np.mean(y_pred[(y_true==0) & (gender==0)]) # (1-fpf)-(1-fpm) = fpm-fpf\n","print(\"Statistical Parity: \",SP)\n","print(\"True Positive Rate Difference (Equal Opportunity): \",EO)\n","print(\"True Negative Rate Difference: \",TNRD)"],"metadata":{"id":"8Zee40pDKymM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true_flat = y_true\n","y_pred_flat = y_pred\n","gender_flat = gender\n","\n","unique_genders = set(gender_flat)\n","\n","# Plot confusion matrix for each gender\n","for gender in unique_genders:\n","    y_true_gender = [y_true_flat[i] for i in range(len(y_true_flat)) if gender_flat[i] == gender]\n","    y_pred_gender = [y_pred_flat[i] for i in range(len(y_pred_flat)) if gender_flat[i] == gender]\n","\n","    cm = confusion_matrix(y_true_gender, y_pred_gender)\n","\n","    plt.figure(figsize=(6, 4))\n","    sns.set(font_scale=1.5)\n","    sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues', cbar=False)\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    if gender==0:\n","      gen = 'Male'\n","    else:\n","      gen = 'Female'\n","    plt.title(f'Confusion Matrix for Gender: {gen}')\n","    plt.show()"],"metadata":{"id":"7uEir8boK01v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"myftn2HgK22L"}},{"cell_type":"markdown","source":["# Use the results from f and g Regression to create f'"],"metadata":{"id":"exI-ELLILEP_"}},{"cell_type":"markdown","source":["## Creating new dataset for f' with results of g and f"],"metadata":{"id":"qoNybzEgOcYm"}},{"cell_type":"code","source":["bias_in_bios_dataset = load_dataset(\"LabHC/bias_in_bios\")\n","bias_in_bios_dataset"],"metadata":{"id":"XEF9hRI7LHlA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nurse = 0   Physician = 1\n","def filter_and_change_values(example):\n","    if example['profession'] == 13:\n","        example['profession'] = 0\n","    elif example['profession'] == 19:\n","        example['profession'] = 1\n","    else:\n","        example['profession'] = None\n","    return example\n","\n","for split in ['train', 'dev', 'test']:\n","    bias_in_bios_dataset[split] = bias_in_bios_dataset[split].map(filter_and_change_values).filter(lambda x: x['profession'] is not None)\n"],"metadata":{"id":"MBqbGWr4OrKH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['hard_text'], truncation=True)\n","\n","tokenized_datasets = bias_in_bios_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['hard_text'])\n","tokenized_datasets = tokenized_datasets.rename_column('profession','labels')\n","tokenized_datasets = tokenized_datasets.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"6g51pmzgOuqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_dataloader = DataLoader(\n","   tokenized_datasets['dev'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"BSwMJuToOwjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint_f = \"MoGP/f_x\"\n","model_f = AutoModelForSequenceClassification.from_pretrained(checkpoint_f, num_labels=2)\n","model_f.to(device)\n","\n","checkpoint_g = \"MoGP/g_x_reg_new_4e\"\n","model_g = AutoModelForSequenceClassification.from_pretrained(checkpoint_g, problem_type=\"regression\", num_labels=1)\n","model_g.to(device)"],"metadata":{"id":"HZuYGFvKOx_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_yg_labels(predictions, labels, sensitive_attribute):\n","    new_labels = np.zeros_like(predictions)\n","    for i in range(len(predictions)):\n","      # False negative for women\n","      if labels[i] == 1 and predictions[i] == 0 and sensitive_attribute[i] == 1:\n","          new_labels[i] = 1\n","      # False positive for men\n","      elif labels[i] == 0 and predictions[i] == 1 and sensitive_attribute[i] == 0:\n","          new_labels[i] = -1\n","      # The rest of the wrong predictions (false negative for men and false positive for women) - should I add this?\n","      elif (labels[i] == 0 and predictions[i] == 1 and sensitive_attribute[i] == 1) or (labels[i] == 1 and predictions[i] == 0 and sensitive_attribute[i] == 0):\n","        new_labels[i] = -2\n","    return new_labels\n","\n","f_labels = []\n","g_labels = []\n","y_g = []\n","\n","model_f.eval()\n","model_g.eval()\n","\n","for batch in dev_dataloader:\n","    labels = batch['labels'].to(device)\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    token_type_ids = batch['token_type_ids'].to(device)\n","    sensitive_attribute = batch['gender'].to(device)\n","\n","\n","    with torch.no_grad():\n","        outputs_f = model_f(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        outputs_g = model_g(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","\n","    f_logits = outputs_f.logits\n","    #f_predictions = torch.argmax(f_logits, dim=-1).cpu().numpy()\n","    f_predictions = torch.nn.functional.softmax(f_logits, dim=-1)[:, 1].cpu().numpy()\n","    f_predictions_for_g = torch.argmax(f_logits, dim=-1)\n","\n","    predictions_np = f_predictions_for_g.cpu().numpy()\n","    labels_np = labels.cpu().numpy()\n","    sensitive_attribute_np = sensitive_attribute.cpu().numpy()\n","\n","    g_logits = outputs_g.logits\n","    g_predictions = g_logits.squeeze().cpu().numpy()\n","\n","    y_g_labels = calculate_yg_labels(predictions_np, labels_np, sensitive_attribute_np)\n","\n","    f_labels.extend(f_predictions)\n","    g_labels.extend(g_predictions)\n","    y_g.extend(y_g_labels)"],"metadata":{"id":"csc11YKfO0Pc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f_labels = np.array(f_labels)\n","g_labels = np.array(g_labels)\n","texts = bias_in_bios_dataset['dev']['hard_text']\n","labels = bias_in_bios_dataset['dev']['profession']\n","genders = bias_in_bios_dataset['dev']['gender']\n","\n","data_dict = {\n","    'hard_text': texts,\n","    'gender': genders,\n","    'labels': labels,\n","    'f_labels': f_labels,\n","    'g_labels': g_labels,\n","    'y_g': y_g\n","}\n","\n","datasets_f_prime = Dataset.from_dict(data_dict)\n","datasets_f_prime"],"metadata":{"id":"NrJwEE5uO6w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_g = pd.DataFrame(datasets_f_prime)\n","dataset_g.to_csv(\"fpdataset.csv\", index=False)"],"metadata":{"id":"sYKEt9LQO_m1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/f_prime_dataset_reg_dev\"\n","access_token = \"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\"\n","csv_file_path = \"fpdataset.csv\"\n","\n","api = HfApi()\n","\n","commit_message = \"Add dataset file\"\n","api.upload_file(\n","    path_or_fileobj=csv_file_path,\n","    path_in_repo=\"fpdataset.csv\",\n","    repo_id=hub_repo_name,\n","    token=access_token,\n","    commit_message=commit_message,\n","    repo_type=\"dataset\"\n",")"],"metadata":{"id":"RBhGCzt3PBlS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training set for f'"],"metadata":{"id":"Fg9HnXwOPEI0"}},{"cell_type":"code","source":["f_prime_dataset_train = load_dataset(\"MoGP/f_prime_dataset_reg\")\n","f_prime_dataset_dev = load_dataset(\"MoGP/f_prime_dataset_reg_dev\")"],"metadata":{"id":"WC47RDdMPGGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = f_prime_dataset_train['train'].to_pandas()\n","\n","majority_class = data[data['y_g'] == 1]\n","minority_class = data[data['y_g'] == -1]\n","zero_class = data[data['y_g'] == 0]\n","\n","# remove some zeros randomly\n","zeros_sample = zero_class.sample(frac=0.019, random_state=42)\n","\n","# Oversample minority class\n","minority_class_oversampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n","\n","balanced_data = pd.concat([majority_class, minority_class_oversampled, zeros_sample])\n","balanced_dataset = Dataset.from_pandas(balanced_data, split='train')"],"metadata":{"id":"x3spq43SPIF5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_pandas = pd.DataFrame(balanced_dataset['y_g'])\n","class_counts = labels_pandas.value_counts().sort_values(ascending=False)\n","print(class_counts)"],"metadata":{"id":"tIsV3emWPQZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['hard_text'], truncation=True)\n","\n","tokenized_datasets = balanced_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['hard_text'])\n","tokenized_datasets = tokenized_datasets.with_format('torch')\n","\n","\n","tokenized_datasets_dev = f_prime_dataset_dev.map(tokenize_function, batched=True)\n","tokenized_datasets_dev = tokenized_datasets_dev.remove_columns(['hard_text'])\n","tokenized_datasets_dev = tokenized_datasets_dev.with_format('torch')\n","\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"uzvxlJYqPTWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(\n","   tokenized_datasets, shuffle=True, batch_size=20, collate_fn=data_collator\n",")\n","dev_dataloader = DataLoader(\n","   tokenized_datasets_dev['train'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"ECJaNiiwPW3j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Use the results from f an g on the evaluation set to create f'"],"metadata":{"id":"JXfgpMkLPkNz"}},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","gc.collect()\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"],"metadata":{"id":"wRW5iRE6Pkuo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def custom_loss(y_g_output, f_output, fprime_output, alpha=0.0): #alpha=1.0\n","    mse_loss = nn.MSELoss()\n","    regularization_term = mse_loss(f_output, fprime_output)\n","    epsilon = 1e-8\n","    log_fprime_output = torch.log(fprime_output + epsilon)\n","    beta=10.0\n","    left = torch.sum((y_g_output * log_fprime_output * -1) + (beta * (1 - y_g_output**2) * regularization_term))\n","    combined_loss = left + alpha * regularization_term\n","    return combined_loss, left, regularization_term\n","\n","def train_fprime(train_dataloader_fprime, num_epochs=2, alpha=0.0): #alpha=1.0\n","    # Initialize f' model\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","    checkpoint = \"MoGP/f_x\"\n","    model_fprime = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","    model_fprime.to(device)\n","\n","    optimizer_fprime = AdamW(model_fprime.parameters(), lr=5e-6) # lr=5e-7\n","    num_training_steps = num_epochs * len(train_dataloader_fprime)\n","    lr_scheduler_fprime = get_scheduler(\n","        \"linear\",\n","        optimizer=optimizer_fprime,\n","        num_warmup_steps=0,\n","        num_training_steps=num_training_steps\n","    )\n","\n","    progress_bar = tqdm(range(num_training_steps))\n","    left_losses = []\n","    right_losses = []\n","    model_fprime.train()\n","    for epoch in range(num_epochs):\n","        for batch in train_dataloader_fprime:\n","            labels = batch['labels'].to(device)\n","            g_output = batch['g_labels'].to(device)\n","            f_output = batch['f_labels'].to(device)\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            token_type_ids = batch['token_type_ids'].to(device)\n","\n","            # Get output from f'\n","\n","            outputs_fprime = model_fprime(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","            fprime_logits = outputs_fprime.logits\n","            fprime_output = torch.nn.functional.softmax(fprime_logits, dim=-1)[:, 1]  # Taking softmax and then second column\n","\n","            # Calculate custom loss\n","            loss, left, right = custom_loss(g_output, f_output, fprime_output, alpha)\n","\n","            loss.backward()\n","\n","            print(f\"g(x):{g_output}\")\n","            print(f\"f(x):{f_output}\")\n","            print(f\"f'(x):{fprime_output}\")\n","            print(\"______________________________________________\")\n","\n","            optimizer_fprime.step()\n","            lr_scheduler_fprime.step()\n","            optimizer_fprime.zero_grad()\n","            progress_bar.update(1)\n","            left_losses.append(left.item())\n","            right_losses.append(right.item())\n","\n","    return model_fprime, left_losses, right_losses\n","\n","model_fprime, left_losses, right_losses = train_fprime(train_dataloader, num_epochs=2, alpha=0.0)  #alpha=1.0\n"],"metadata":{"id":"DeZ6exojPmUD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the losses\n","#lsosses = left_losses[0::100]\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(left_losses, label='Left Loss')\n","plt.xlabel('Training Step')\n","plt.ylabel('Loss')\n","plt.title(\"Left Loss (Argmin -g(x)f'(x)) over Training Steps\")\n","plt.legend()\n","\n","#rlosses = right_losses[0::100]\n","plt.subplot(1, 2, 2)\n","plt.plot(right_losses, label='Right Loss')\n","plt.xlabel('Training Step')\n","plt.ylabel('Loss')\n","plt.title(\"Regularization Term (|f(x)-f'(x)|) over Training Steps\")\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"TycS36VyPrt-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub_repo_name = \"MoGP/f_prime_reg_4\"\n","access_token = \"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\"\n","\n","# Save the model and tokenizer to the Hub\n","model_fprime.push_to_hub(hub_repo_name, use_auth_token=access_token)\n","tokenizer.push_to_hub(hub_repo_name, use_auth_token=access_token)"],"metadata":{"id":"ueK67B62PuRV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation of f'"],"metadata":{"id":"h_y8kd38P52T"}},{"cell_type":"code","source":["bias_in_bios_dataset = load_dataset(\"LabHC/bias_in_bios\")\n","bias_in_bios_dataset"],"metadata":{"id":"fJefjcdJP82x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nurse = 0   Physician = 1\n","def filter_and_change_values(example):\n","    if example['profession'] == 13:\n","        example['profession'] = 0\n","    elif example['profession'] == 19:\n","        example['profession'] = 1\n","    else:\n","        example['profession'] = None\n","    return example\n","\n","for split in ['train', 'dev', 'test']:\n","    bias_in_bios_dataset[split] = bias_in_bios_dataset[split].map(filter_and_change_values).filter(lambda x: x['profession'] is not None)\n"],"metadata":{"id":"R4oOPiXzP-wx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","def tokenize_function(examples):\n","  return tokenizer(examples['hard_text'], truncation=True)\n","\n","tokenized_datasets = bias_in_bios_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['hard_text'])\n","tokenized_datasets = tokenized_datasets.rename_column('profession','labels')\n","tokenized_datasets = tokenized_datasets.with_format('torch')\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"PCG4ysNFQA0R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataloader = DataLoader(\n","   tokenized_datasets['test'], batch_size=20, collate_fn=data_collator\n",")"],"metadata":{"id":"8a4rFzZRQDN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","checkpoint = \"MoGP/f_prime_reg_4\"\n","model_fprime = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","\n","model_fprime.to(device)\n","print(device)"],"metadata":{"id":"fMDAC1sdQFH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = []\n","y_pred = []\n","gender = []\n","metric = load_metric(\"glue\",\"mrpc\")\n","model_fprime.eval()\n","\n","for batch in test_dataloader:\n","  labels = batch['labels'].to(device)\n","  input_ids = batch['input_ids'].to(device)\n","  attention_mask = batch['attention_mask'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  token_type_ids = batch['token_type_ids'].to(device)\n","  sex = batch['gender'].to(device)\n","  with torch.no_grad():\n","    outputs = model_fprime(input_ids, labels=labels, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","  logits = outputs.logits\n","  predictions = torch.argmax(logits, dim=-1)\n","  metric.add_batch(predictions=predictions, references=labels)\n","  pred = predictions.cpu().numpy()\n","  lab = labels.cpu().numpy()\n","  gen = sex.cpu().numpy()\n","  y_pred.append(pred)\n","  y_true.append(lab)\n","  gender.append(gen)\n","metric.compute()"],"metadata":{"id":"PN4WRRmIQGbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = np.concatenate(y_pred)\n","y_true = np.concatenate(y_true)\n","gender = np.concatenate(gender)\n","\n","conf_matrix = confusion_matrix(y_true,y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)"],"metadata":{"id":"DkSnCYEeQJxl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[0,1]) #nurse,physician\n","disp.plot()\n","plt.savefig(\"conf.png\")\n","plt.show()"],"metadata":{"id":"sMMrgwfbQLmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fairness metrics : female=1 , male=0\n","SP = np.mean(y_pred[gender==0]) - np.mean(y_pred[gender==1])\n","EO = np.mean(y_pred[(y_true==1) & (gender==0)]) - np.mean(y_pred[(y_true==1) & (gender==1)])\n","TNRD = np.mean(y_pred[(y_true==0) & (gender==1)]) - np.mean(y_pred[(y_true==0) & (gender==0)]) # (1-fpf)-(1-fpm) = fpm-fpf\n","print(\"Statistical Parity: \",SP)\n","print(\"True Positive Rate Difference (Equal Opportunity): \",EO)\n","print(\"True Negative Rate Difference: \",TNRD)"],"metadata":{"id":"NoB4gfgJQMOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true_flat = y_true\n","y_pred_flat = y_pred\n","gender_flat = gender\n","\n","unique_genders = set(gender_flat)\n","\n","# Plot confusion matrix for each gender\n","for gender in unique_genders:\n","    y_true_gender = [y_true_flat[i] for i in range(len(y_true_flat)) if gender_flat[i] == gender]\n","    y_pred_gender = [y_pred_flat[i] for i in range(len(y_pred_flat)) if gender_flat[i] == gender]\n","\n","    cm = confusion_matrix(y_true_gender, y_pred_gender)\n","\n","    plt.figure(figsize=(6, 4))\n","    sns.set(font_scale=1.5)\n","    sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues', cbar=False)\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    if gender==0:\n","      gen = 'Male'\n","    else:\n","      gen = 'Female'\n","    plt.title(f'Confusion Matrix for Gender: {gen}')\n","    plt.show()"],"metadata":{"id":"MQ0YCgAnQO4e"},"execution_count":null,"outputs":[]}]}